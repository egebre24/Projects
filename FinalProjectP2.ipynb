{"cells":[{"cell_type":"code","source":"import pandas as _hex_pandas\nimport datetime as _hex_datetime\nimport json as _hex_json","execution_count":null,"metadata":{},"outputs":[]},{"cell_type":"code","source":"hex_scheduled = _hex_json.loads(\"false\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_user_email = _hex_json.loads(\"\\\"example-user@example.com\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_run_context = _hex_json.loads(\"\\\"logic\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_timezone = _hex_json.loads(\"\\\"US/Eastern\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_id = _hex_json.loads(\"\\\"d4d16f54-4573-453e-a8de-ecb82a17c382\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_name = _hex_json.loads(\"\\\"FinalProjectP2\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_status = _hex_json.loads(\"\\\"\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_categories = _hex_json.loads(\"[]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_color_palette = _hex_json.loads(\"[\\\"#4C78A8\\\",\\\"#F58518\\\",\\\"#E45756\\\",\\\"#72B7B2\\\",\\\"#54A24B\\\",\\\"#EECA3B\\\",\\\"#B279A2\\\",\\\"#FF9DA6\\\",\\\"#9D755D\\\",\\\"#BAB0AC\\\"]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom imblearn.over_sampling import SMOTE\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"finalData.csv\")\n\nvehicle_crimes = [\"Theft From Motor Vehicle\", \"Motor Vehicle Theft\", \"Theft of Motor Vehicle Parts from Vehicle\"]\n\ndata['Crime_Type'] = data['Crime_Type'].apply(lambda x: 0 if x in vehicle_crimes else 1)\n\nsocioeconomic_features = ['TotalPopulationEstimate', 'HousingUnitsOwnerOccupied',\n                          'HousingUnitsRenterOccupied', 'UnemploymentRateAge16to19',\n                          'UnemploymentRateAge20to24', 'UnemploymentRateAge25to44',\n                          'UnemploymentRateAge55to64', 'UnemploymentRateAge65to74',\n                          'UnemploymentRateAge75AndOver']\n\nfeatures = data[socioeconomic_features]\ntarget = data['Crime_Type']\n\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(features)\n\nX_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.30, random_state=42)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vehicle_crime_count = (data['Crime_Type'] == 0).sum()\nother_crime_count = (data['Crime_Type'] == 1).sum()\n\nprint(\"Number of Vehicle-Related Crimes:\", vehicle_crime_count)\nprint(\"Number of Other Crimes:\", other_crime_count)","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Number of Vehicle-Related Crimes: 45798\nNumber of Other Crimes: 120583\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"lr_model_unbalanced = LogisticRegression(max_iter=1000)\nlr_model_unbalanced.fit(X_train, y_train)\nlr_predictions_unbalanced = lr_model_unbalanced.predict(X_test)\n\nprint(\"Unbalanced Logistic Regression Accuracy:\", accuracy_score(y_test, lr_predictions_unbalanced))\nprint(\"Unbalanced Logistic Regression Report:\\n\", classification_report(y_test, lr_predictions_unbalanced))\n\nrf_model_unbalanced = RandomForestClassifier(n_estimators=100)\nrf_model_unbalanced.fit(X_train, y_train)\nrf_predictions_unbalanced = rf_model_unbalanced.predict(X_test)\n\nprint(\"Unbalanced Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions_unbalanced))\nprint(\"Unbalanced Random Forest Report:\\n\", classification_report(y_test, rf_predictions_unbalanced))\n\ndt_model_unbalanced = DecisionTreeClassifier()\ndt_model_unbalanced.fit(X_train, y_train)\ndt_predictions_unbalanced = dt_model_unbalanced.predict(X_test)\n\nprint(\"Unbalanced Decision Tree Accuracy:\", accuracy_score(y_test, dt_predictions_unbalanced))\nprint(\"Unbalanced Decision Tree Report:\\n\", classification_report(y_test, dt_predictions_unbalanced))\n\nnb_model_unbalanced = GaussianNB()\nnb_model_unbalanced.fit(X_train, y_train)\nnb_predictions_unbalanced = nb_model_unbalanced.predict(X_test)\n\nprint(\"Unbalanced Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions_unbalanced))\nprint(\"Unbalanced Naive Bayes Report:\\n\", classification_report(y_test, nb_predictions_unbalanced))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Unbalanced Logistic Regression Accuracy: 0.723630171291195\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nUnbalanced Logistic Regression Report:\n               precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00     13795\n           1       0.72      1.00      0.84     36120\n\n    accuracy                           0.72     49915\n   macro avg       0.36      0.50      0.42     49915\nweighted avg       0.52      0.72      0.61     49915\n\nUnbalanced Random Forest Accuracy: 0.7235901031753982\nUnbalanced Random Forest Report:\n               precision    recall  f1-score   support\n\n           0       0.33      0.00      0.00     13795\n           1       0.72      1.00      0.84     36120\n\n    accuracy                           0.72     49915\n   macro avg       0.53      0.50      0.42     49915\nweighted avg       0.62      0.72      0.61     49915\n\nUnbalanced Decision Tree Accuracy: 0.7236101372332966\nUnbalanced Decision Tree Report:\n               precision    recall  f1-score   support\n\n           0       0.43      0.00      0.00     13795\n           1       0.72      1.00      0.84     36120\n\n    accuracy                           0.72     49915\n   macro avg       0.58      0.50      0.42     49915\nweighted avg       0.64      0.72      0.61     49915\n\nUnbalanced Naive Bayes Accuracy: 0.697185214865271\nUnbalanced Naive Bayes Report:\n               precision    recall  f1-score   support\n\n           0       0.32      0.08      0.13     13795\n           1       0.73      0.93      0.82     36120\n\n    accuracy                           0.70     49915\n   macro avg       0.52      0.51      0.47     49915\nweighted avg       0.61      0.70      0.63     49915\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"lr_model = LogisticRegression(max_iter=1000, class_weight='balanced')\nlr_model.fit(X_train, y_train)\nlr_predictions = lr_model.predict(X_test)\n\nprint(\"Balanced Logistic Regression Accuracy:\", accuracy_score(y_test, lr_predictions))\nprint(\"Balanced Logistic Regression Report:\\n\", classification_report(y_test, lr_predictions))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Balanced Logistic Regression Accuracy: 0.5917459681458479\nBalanced Logistic Regression Report:\n               precision    recall  f1-score   support\n\n           0       0.31      0.37      0.34     13795\n           1       0.74      0.67      0.71     36120\n\n    accuracy                           0.59     49915\n   macro avg       0.52      0.52      0.52     49915\nweighted avg       0.62      0.59      0.60     49915\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced')\nrf_model.fit(X_train, y_train)\nrf_predictions = rf_model.predict(X_test)\n\nprint(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions))\nprint(\"Random Forest Report:\\n\", classification_report(y_test, rf_predictions))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Random Forest Accuracy: 0.5641190023039167\nRandom Forest Report:\n               precision    recall  f1-score   support\n\n           0       0.31      0.47      0.37     13795\n           1       0.75      0.60      0.67     36120\n\n    accuracy                           0.56     49915\n   macro avg       0.53      0.53      0.52     49915\nweighted avg       0.63      0.56      0.58     49915\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\ngb_model.fit(X_train, y_train)\ngb_predictions = gb_model.predict(X_test)\n\nprint(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gb_predictions))\nprint(\"Gradient Boosting Report:\\n\", classification_report(y_test, gb_predictions))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Gradient Boosting Accuracy: 0.7235901031753982\nGradient Boosting Report:\n               precision    recall  f1-score   support\n\n           0       0.33      0.00      0.00     13795\n           1       0.72      1.00      0.84     36120\n\n    accuracy                           0.72     49915\n   macro avg       0.53      0.50      0.42     49915\nweighted avg       0.62      0.72      0.61     49915\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"dt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train, y_train)\ndt_predictions = dt_model.predict(X_test)\n\nprint(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_predictions))\nprint(\"Decision Tree Report:\\n\", classification_report(y_test, dt_predictions))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Decision Tree Accuracy: 0.7236101372332966\nDecision Tree Report:\n               precision    recall  f1-score   support\n\n           0       0.43      0.00      0.00     13795\n           1       0.72      1.00      0.84     36120\n\n    accuracy                           0.72     49915\n   macro avg       0.58      0.50      0.42     49915\nweighted avg       0.64      0.72      0.61     49915\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\nxgb_model.fit(X_train, y_train)\nxgb_predictions = xgb_model.predict(X_test)\n\nprint(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_predictions))\nprint(\"XGBoost Report:\\n\", classification_report(y_test, xgb_predictions))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\nXGBoost Accuracy: 0.7235901031753982\nXGBoost Report:\n               precision    recall  f1-score   support\n\n           0       0.33      0.00      0.00     13795\n           1       0.72      1.00      0.84     36120\n\n    accuracy                           0.72     49915\n   macro avg       0.53      0.50      0.42     49915\nweighted avg       0.62      0.72      0.61     49915\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"nb_model = GaussianNB()\nnb_model.fit(X_train, y_train)\nnb_predictions = nb_model.predict(X_test)\n\nprint(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions))\nprint(\"Naive Bayes Report:\\n\", classification_report(y_test, nb_predictions))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Naive Bayes Accuracy: 0.697185214865271\nNaive Bayes Report:\n               precision    recall  f1-score   support\n\n           0       0.32      0.08      0.13     13795\n           1       0.73      0.93      0.82     36120\n\n    accuracy                           0.70     49915\n   macro avg       0.52      0.51      0.47     49915\nweighted avg       0.61      0.70      0.63     49915\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"smote = SMOTE(random_state=42)\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\nskf = StratifiedKFold(n_splits=5)\n\nfor name, model in [(\"Logistic Regression\", LogisticRegression(max_iter=1000, class_weight='balanced')),\n                    (\"Random Forest\", RandomForestClassifier(n_estimators=100, class_weight='balanced')),\n                    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n                    (\"Naive Bayes\", GaussianNB())]:\n    print(f\"{name} - Cross-validation Results for Vehicle-Related Crime Prediction:\")\n    for score_name, score_func in [('Precision (class 0)', precision_score), \n                                   ('Recall (class 0)', recall_score), \n                                   ('F1 Score (class 0)', f1_score)]:\n        cv_results = cross_val_score(model, X_train_smote, y_train_smote, cv=skf, \n                                     scoring=make_scorer(score_func, zero_division=0, average=None, labels=[0]))\n        print(f\"  {score_name}: {np.mean(cv_results)}\")\n    print()\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Logistic Regression - Cross-validation Results for Vehicle-Related Crime Prediction:\n  Precision (class 0): 0.5392532095749848\n  Recall (class 0): 0.38029667557383895\n  F1 Score (class 0): 0.4460331005617083\n\nRandom Forest - Cross-validation Results for Vehicle-Related Crime Prediction:\n  Precision (class 0): 0.5385176269723595\n  Recall (class 0): 0.46284169689796784\n  F1 Score (class 0): 0.49781950525399415\n\nDecision Tree - Cross-validation Results for Vehicle-Related Crime Prediction:\n  Precision (class 0): 0.5385112826584828\n  Recall (class 0): 0.4628298576746209\n  F1 Score (class 0): 0.4978099416774707\n\nNaive Bayes - Cross-validation Results for Vehicle-Related Crime Prediction:\n  Precision (class 0): 0.5285984503969341\n  Recall (class 0): 0.39213619258847515\n  F1 Score (class 0): 0.4502529357967221\n\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nparam_grid_lr = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n    'max_iter': [100, 500, 1000]\n}\n\nlr_model = LogisticRegression(class_weight='balanced')\n\ngrid_search_lr = GridSearchCV(estimator=lr_model, param_grid=param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\ngrid_search_lr.fit(X_train, y_train)\n\nprint(\"Best Parameters for Logistic Regression:\", grid_search_lr.best_params_)\nprint(\"Best Score for Logistic Regression:\", grid_search_lr.best_score_)\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Fitting 5 folds for each of 54 candidates, totalling 270 fits\n[CV] END ............C=0.001, max_iter=100, solver=newton-cg; total time=  18.0s\n[CV] END ............C=0.001, max_iter=100, solver=newton-cg; total time=  20.3s\n[CV] END ............C=0.001, max_iter=100, solver=newton-cg; total time=  19.9s\n[CV] END ............C=0.001, max_iter=100, solver=newton-cg; total time=  19.0s\n[CV] END ............C=0.001, max_iter=100, solver=newton-cg; total time=  20.3s\n[CV] END ................C=0.001, max_iter=100, solver=lbfgs; total time=   4.4s\n[CV] END ................C=0.001, max_iter=100, solver=lbfgs; total time=   4.5s\n[CV] END ................C=0.001, max_iter=100, solver=lbfgs; total time=   4.7s\n[CV] END ................C=0.001, max_iter=100, solver=lbfgs; total time=   4.4s\n[CV] END ................C=0.001, max_iter=100, solver=lbfgs; total time=   4.5s\n[CV] END ............C=0.001, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ............C=0.001, max_iter=100, solver=liblinear; total time=   0.3s\n[CV] END ............C=0.001, max_iter=100, solver=liblinear; total time=   0.2s\n[CV] END ............C=0.001, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ............C=0.001, max_iter=100, solver=liblinear; total time=   0.3s\n[CV] END ............C=0.001, max_iter=500, solver=newton-cg; total time=  18.8s\n[CV] END ............C=0.001, max_iter=500, solver=newton-cg; total time=  19.0s\n[CV] END ............C=0.001, max_iter=500, solver=newton-cg; total time=  19.1s\n[CV] END ............C=0.001, max_iter=500, solver=newton-cg; total time=  19.5s\n[CV] END ............C=0.001, max_iter=500, solver=newton-cg; total time=  20.3s\n[CV] END ................C=0.001, max_iter=500, solver=lbfgs; total time=   4.7s\n[CV] END ................C=0.001, max_iter=500, solver=lbfgs; total time=   4.1s\n[CV] END ................C=0.001, max_iter=500, solver=lbfgs; total time=   4.7s\n[CV] END ................C=0.001, max_iter=500, solver=lbfgs; total time=   4.5s\n[CV] END ................C=0.001, max_iter=500, solver=lbfgs; total time=   4.0s\n[CV] END ............C=0.001, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END ............C=0.001, max_iter=500, solver=liblinear; total time=   0.5s\n[CV] END ............C=0.001, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END ............C=0.001, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END ............C=0.001, max_iter=500, solver=liblinear; total time=   0.2s\n[CV] END ...........C=0.001, max_iter=1000, solver=newton-cg; total time=  18.9s\n[CV] END ...........C=0.001, max_iter=1000, solver=newton-cg; total time=  20.7s\n[CV] END ...........C=0.001, max_iter=1000, solver=newton-cg; total time=  22.1s\n[CV] END ...........C=0.001, max_iter=1000, solver=newton-cg; total time=  21.5s\n[CV] END ...........C=0.001, max_iter=1000, solver=newton-cg; total time=  21.8s\n[CV] END ...............C=0.001, max_iter=1000, solver=lbfgs; total time=   5.0s\n[CV] END ...............C=0.001, max_iter=1000, solver=lbfgs; total time=   4.2s\n[CV] END ...............C=0.001, max_iter=1000, solver=lbfgs; total time=   4.9s\n[CV] END ...............C=0.001, max_iter=1000, solver=lbfgs; total time=   4.9s\n[CV] END ...............C=0.001, max_iter=1000, solver=lbfgs; total time=   4.4s\n[CV] END ...........C=0.001, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ...........C=0.001, max_iter=1000, solver=liblinear; total time=   0.2s\n[CV] END ...........C=0.001, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ...........C=0.001, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ...........C=0.001, max_iter=1000, solver=liblinear; total time=   0.2s\n[CV] END .............C=0.01, max_iter=100, solver=newton-cg; total time=  23.4s\n[CV] END .............C=0.01, max_iter=100, solver=newton-cg; total time=  24.1s\n[CV] END .............C=0.01, max_iter=100, solver=newton-cg; total time=  20.3s\n[CV] END .............C=0.01, max_iter=100, solver=newton-cg; total time=  21.5s\n[CV] END .............C=0.01, max_iter=100, solver=newton-cg; total time=  20.5s\n[CV] END .................C=0.01, max_iter=100, solver=lbfgs; total time=   5.2s\n[CV] END .................C=0.01, max_iter=100, solver=lbfgs; total time=   4.7s\n[CV] END .................C=0.01, max_iter=100, solver=lbfgs; total time=   5.3s\n[CV] END .................C=0.01, max_iter=100, solver=lbfgs; total time=   5.3s\n[CV] END .................C=0.01, max_iter=100, solver=lbfgs; total time=   4.6s\n[CV] END .............C=0.01, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END .............C=0.01, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END .............C=0.01, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END .............C=0.01, max_iter=100, solver=liblinear; total time=   0.5s\n[CV] END .............C=0.01, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END .............C=0.01, max_iter=500, solver=newton-cg; total time=  23.8s\n[CV] END .............C=0.01, max_iter=500, solver=newton-cg; total time=  24.3s\n[CV] END .............C=0.01, max_iter=500, solver=newton-cg; total time=  21.4s\n[CV] END .............C=0.01, max_iter=500, solver=newton-cg; total time=  21.7s\n[CV] END .............C=0.01, max_iter=500, solver=newton-cg; total time=  18.9s\n[CV] END .................C=0.01, max_iter=500, solver=lbfgs; total time=   4.9s\n[CV] END .................C=0.01, max_iter=500, solver=lbfgs; total time=   3.9s\n[CV] END .................C=0.01, max_iter=500, solver=lbfgs; total time=   4.6s\n[CV] END .................C=0.01, max_iter=500, solver=lbfgs; total time=   4.4s\n[CV] END .................C=0.01, max_iter=500, solver=lbfgs; total time=   4.3s\n[CV] END .............C=0.01, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END .............C=0.01, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END .............C=0.01, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END .............C=0.01, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END .............C=0.01, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END ............C=0.01, max_iter=1000, solver=newton-cg; total time=  20.3s\n[CV] END ............C=0.01, max_iter=1000, solver=newton-cg; total time=  21.8s\n[CV] END ............C=0.01, max_iter=1000, solver=newton-cg; total time=  20.2s\n[CV] END ............C=0.01, max_iter=1000, solver=newton-cg; total time=  19.6s\n[CV] END ............C=0.01, max_iter=1000, solver=newton-cg; total time=  19.7s\n[CV] END ................C=0.01, max_iter=1000, solver=lbfgs; total time=   4.4s\n[CV] END ................C=0.01, max_iter=1000, solver=lbfgs; total time=   4.4s\n[CV] END ................C=0.01, max_iter=1000, solver=lbfgs; total time=   4.6s\n[CV] END ................C=0.01, max_iter=1000, solver=lbfgs; total time=   4.6s\n[CV] END ................C=0.01, max_iter=1000, solver=lbfgs; total time=   4.2s\n[CV] END ............C=0.01, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ............C=0.01, max_iter=1000, solver=liblinear; total time=   0.4s\n[CV] END ............C=0.01, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ............C=0.01, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ............C=0.01, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ..............C=0.1, max_iter=100, solver=newton-cg; total time=  22.4s\n[CV] END ..............C=0.1, max_iter=100, solver=newton-cg; total time=  18.5s\n[CV] END ..............C=0.1, max_iter=100, solver=newton-cg; total time=  19.5s\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n[CV] END ..............C=0.1, max_iter=100, solver=newton-cg; total time=  55.7s\n[CV] END ..............C=0.1, max_iter=100, solver=newton-cg; total time=  19.3s\n[CV] END ..................C=0.1, max_iter=100, solver=lbfgs; total time=   4.8s\n[CV] END ..................C=0.1, max_iter=100, solver=lbfgs; total time=   4.2s\n[CV] END ..................C=0.1, max_iter=100, solver=lbfgs; total time=   4.5s\n[CV] END ..................C=0.1, max_iter=100, solver=lbfgs; total time=   4.7s\n[CV] END ..................C=0.1, max_iter=100, solver=lbfgs; total time=   4.6s\n[CV] END ..............C=0.1, max_iter=100, solver=liblinear; total time=   0.3s\n[CV] END ..............C=0.1, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ..............C=0.1, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ..............C=0.1, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ..............C=0.1, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ..............C=0.1, max_iter=500, solver=newton-cg; total time=  22.2s\n[CV] END ..............C=0.1, max_iter=500, solver=newton-cg; total time=  18.6s\n[CV] END ..............C=0.1, max_iter=500, solver=newton-cg; total time=  21.1s\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n[CV] END ..............C=0.1, max_iter=500, solver=newton-cg; total time=  58.4s\n[CV] END ..............C=0.1, max_iter=500, solver=newton-cg; total time=  19.8s\n[CV] END ..................C=0.1, max_iter=500, solver=lbfgs; total time=   4.8s\n[CV] END ..................C=0.1, max_iter=500, solver=lbfgs; total time=   4.8s\n[CV] END ..................C=0.1, max_iter=500, solver=lbfgs; total time=   4.6s\n[CV] END ..................C=0.1, max_iter=500, solver=lbfgs; total time=   4.9s\n[CV] END ..................C=0.1, max_iter=500, solver=lbfgs; total time=   4.7s\n[CV] END ..............C=0.1, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END ..............C=0.1, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END ..............C=0.1, max_iter=500, solver=liblinear; total time=   0.2s\n[CV] END ..............C=0.1, max_iter=500, solver=liblinear; total time=   0.6s\n[CV] END ..............C=0.1, max_iter=500, solver=liblinear; total time=   0.2s\n[CV] END .............C=0.1, max_iter=1000, solver=newton-cg; total time=  22.0s\n[CV] END .............C=0.1, max_iter=1000, solver=newton-cg; total time=  19.5s\n[CV] END .............C=0.1, max_iter=1000, solver=newton-cg; total time=  19.6s\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n  warn('The line search algorithm did not converge', LineSearchWarning)\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n  warnings.warn(\"Line Search failed\")\n[CV] END .............C=0.1, max_iter=1000, solver=newton-cg; total time=  55.5s\n[CV] END .............C=0.1, max_iter=1000, solver=newton-cg; total time=  18.8s\n[CV] END .................C=0.1, max_iter=1000, solver=lbfgs; total time=   4.7s\n[CV] END .................C=0.1, max_iter=1000, solver=lbfgs; total time=   4.0s\n[CV] END .................C=0.1, max_iter=1000, solver=lbfgs; total time=   4.5s\n[CV] END .................C=0.1, max_iter=1000, solver=lbfgs; total time=   4.7s\n[CV] END .................C=0.1, max_iter=1000, solver=lbfgs; total time=   4.8s\n[CV] END .............C=0.1, max_iter=1000, solver=liblinear; total time=   0.5s\n[CV] END .............C=0.1, max_iter=1000, solver=liblinear; total time=   0.4s\n[CV] END .............C=0.1, max_iter=1000, solver=liblinear; total time=   0.4s\n[CV] END .............C=0.1, max_iter=1000, solver=liblinear; total time=   0.2s\n[CV] END .............C=0.1, max_iter=1000, solver=liblinear; total time=   0.5s\n[CV] END ................C=1, max_iter=100, solver=newton-cg; total time=  21.5s\n[CV] END ................C=1, max_iter=100, solver=newton-cg; total time=  19.6s\n[CV] END ................C=1, max_iter=100, solver=newton-cg; total time=  18.4s\n[CV] END ................C=1, max_iter=100, solver=newton-cg; total time=  20.0s\n[CV] END ................C=1, max_iter=100, solver=newton-cg; total time=  19.7s\n[CV] END ....................C=1, max_iter=100, solver=lbfgs; total time=   4.6s\n[CV] END ....................C=1, max_iter=100, solver=lbfgs; total time=   4.1s\n[CV] END ....................C=1, max_iter=100, solver=lbfgs; total time=   4.5s\n[CV] END ....................C=1, max_iter=100, solver=lbfgs; total time=   4.5s\n[CV] END ....................C=1, max_iter=100, solver=lbfgs; total time=   4.9s\n[CV] END ................C=1, max_iter=100, solver=liblinear; total time=   0.5s\n[CV] END ................C=1, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ................C=1, max_iter=100, solver=liblinear; total time=   0.2s\n[CV] END ................C=1, max_iter=100, solver=liblinear; total time=   0.3s\n[CV] END ................C=1, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ................C=1, max_iter=500, solver=newton-cg; total time=  22.5s\n[CV] END ................C=1, max_iter=500, solver=newton-cg; total time=  18.5s\n[CV] END ................C=1, max_iter=500, solver=newton-cg; total time=  18.3s\n[CV] END ................C=1, max_iter=500, solver=newton-cg; total time=  21.2s\n[CV] END ................C=1, max_iter=500, solver=newton-cg; total time=  19.6s\n[CV] END ....................C=1, max_iter=500, solver=lbfgs; total time=   4.9s\n[CV] END ....................C=1, max_iter=500, solver=lbfgs; total time=   4.5s\n[CV] END ....................C=1, max_iter=500, solver=lbfgs; total time=   4.7s\n[CV] END ....................C=1, max_iter=500, solver=lbfgs; total time=   5.0s\n[CV] END ....................C=1, max_iter=500, solver=lbfgs; total time=   4.9s\n[CV] END ................C=1, max_iter=500, solver=liblinear; total time=   0.5s\n[CV] END ................C=1, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END ................C=1, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END ................C=1, max_iter=500, solver=liblinear; total time=   0.2s\n[CV] END ................C=1, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END ...............C=1, max_iter=1000, solver=newton-cg; total time=  21.7s\n[CV] END ...............C=1, max_iter=1000, solver=newton-cg; total time=  19.1s\n[CV] END ...............C=1, max_iter=1000, solver=newton-cg; total time=  18.5s\n[CV] END ...............C=1, max_iter=1000, solver=newton-cg; total time=  20.9s\n[CV] END ...............C=1, max_iter=1000, solver=newton-cg; total time=  19.1s\n[CV] END ...................C=1, max_iter=1000, solver=lbfgs; total time=   4.8s\n[CV] END ...................C=1, max_iter=1000, solver=lbfgs; total time=   4.2s\n[CV] END ...................C=1, max_iter=1000, solver=lbfgs; total time=   4.7s\n[CV] END ...................C=1, max_iter=1000, solver=lbfgs; total time=   4.6s\n[CV] END ...................C=1, max_iter=1000, solver=lbfgs; total time=   4.5s\n[CV] END ...............C=1, max_iter=1000, solver=liblinear; total time=   0.4s\n[CV] END ...............C=1, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ...............C=1, max_iter=1000, solver=liblinear; total time=   0.4s\n[CV] END ...............C=1, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ...............C=1, max_iter=1000, solver=liblinear; total time=   0.2s\n[CV] END ...............C=10, max_iter=100, solver=newton-cg; total time=  21.8s\n[CV] END ...............C=10, max_iter=100, solver=newton-cg; total time=  18.4s\n[CV] END ...............C=10, max_iter=100, solver=newton-cg; total time=  18.8s\n[CV] END ...............C=10, max_iter=100, solver=newton-cg; total time=  20.8s\n[CV] END ...............C=10, max_iter=100, solver=newton-cg; total time=  19.3s\n[CV] END ...................C=10, max_iter=100, solver=lbfgs; total time=   4.4s\n[CV] END ...................C=10, max_iter=100, solver=lbfgs; total time=   4.2s\n[CV] END ...................C=10, max_iter=100, solver=lbfgs; total time=   4.3s\n[CV] END ...................C=10, max_iter=100, solver=lbfgs; total time=   4.7s\n[CV] END ...................C=10, max_iter=100, solver=lbfgs; total time=   4.3s\n[CV] END ...............C=10, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ...............C=10, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ...............C=10, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ...............C=10, max_iter=100, solver=liblinear; total time=   0.2s\n[CV] END ...............C=10, max_iter=100, solver=liblinear; total time=   0.3s\n[CV] END ...............C=10, max_iter=500, solver=newton-cg; total time=  22.5s\n[CV] END ...............C=10, max_iter=500, solver=newton-cg; total time=  19.6s\n[CV] END ...............C=10, max_iter=500, solver=newton-cg; total time=  17.8s\n[CV] END ...............C=10, max_iter=500, solver=newton-cg; total time=  21.0s\n[CV] END ...............C=10, max_iter=500, solver=newton-cg; total time=  18.9s\n[CV] END ...................C=10, max_iter=500, solver=lbfgs; total time=   4.7s\n[CV] END ...................C=10, max_iter=500, solver=lbfgs; total time=   4.2s\n[CV] END ...................C=10, max_iter=500, solver=lbfgs; total time=   4.5s\n[CV] END ...................C=10, max_iter=500, solver=lbfgs; total time=   4.4s\n[CV] END ...................C=10, max_iter=500, solver=lbfgs; total time=   4.5s\n[CV] END ...............C=10, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END ...............C=10, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END ...............C=10, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END ...............C=10, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END ...............C=10, max_iter=500, solver=liblinear; total time=   0.4s\n[CV] END ..............C=10, max_iter=1000, solver=newton-cg; total time=  21.8s\n[CV] END ..............C=10, max_iter=1000, solver=newton-cg; total time=  18.6s\n[CV] END ..............C=10, max_iter=1000, solver=newton-cg; total time=  17.8s\n[CV] END ..............C=10, max_iter=1000, solver=newton-cg; total time=  19.9s\n[CV] END ..............C=10, max_iter=1000, solver=newton-cg; total time=  18.8s\n[CV] END ..................C=10, max_iter=1000, solver=lbfgs; total time=   4.6s\n[CV] END ..................C=10, max_iter=1000, solver=lbfgs; total time=   4.2s\n[CV] END ..................C=10, max_iter=1000, solver=lbfgs; total time=   4.5s\n[CV] END ..................C=10, max_iter=1000, solver=lbfgs; total time=   4.6s\n[CV] END ..................C=10, max_iter=1000, solver=lbfgs; total time=   4.5s\n[CV] END ..............C=10, max_iter=1000, solver=liblinear; total time=   0.2s\n[CV] END ..............C=10, max_iter=1000, solver=liblinear; total time=   0.4s\n[CV] END ..............C=10, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END ..............C=10, max_iter=1000, solver=liblinear; total time=   0.2s\n[CV] END ..............C=10, max_iter=1000, solver=liblinear; total time=   0.4s\n[CV] END ..............C=100, max_iter=100, solver=newton-cg; total time=  21.8s\n[CV] END ..............C=100, max_iter=100, solver=newton-cg; total time=  17.9s\n[CV] END ..............C=100, max_iter=100, solver=newton-cg; total time=  19.3s\n[CV] END ..............C=100, max_iter=100, solver=newton-cg; total time=  20.5s\n[CV] END ..............C=100, max_iter=100, solver=newton-cg; total time=  18.5s\n[CV] END ..................C=100, max_iter=100, solver=lbfgs; total time=   4.5s\n[CV] END ..................C=100, max_iter=100, solver=lbfgs; total time=   3.9s\n[CV] END ..................C=100, max_iter=100, solver=lbfgs; total time=   4.5s\n[CV] END ..................C=100, max_iter=100, solver=lbfgs; total time=   5.0s\n[CV] END ..................C=100, max_iter=100, solver=lbfgs; total time=   4.4s\n[CV] END ..............C=100, max_iter=100, solver=liblinear; total time=   0.5s\n[CV] END ..............C=100, max_iter=100, solver=liblinear; total time=   0.2s\n[CV] END ..............C=100, max_iter=100, solver=liblinear; total time=   0.4s\n[CV] END ..............C=100, max_iter=100, solver=liblinear; total time=   0.2s\n[CV] END ..............C=100, max_iter=100, solver=liblinear; total time=   0.3s\n[CV] END ..............C=100, max_iter=500, solver=newton-cg; total time=  22.0s\n[CV] END ..............C=100, max_iter=500, solver=newton-cg; total time=  18.3s\n[CV] END ..............C=100, max_iter=500, solver=newton-cg; total time=  19.3s\n[CV] END ..............C=100, max_iter=500, solver=newton-cg; total time=  19.9s\n[CV] END ..............C=100, max_iter=500, solver=newton-cg; total time=  18.5s\n[CV] END ..................C=100, max_iter=500, solver=lbfgs; total time=   4.4s\n[CV] END ..................C=100, max_iter=500, solver=lbfgs; total time=   4.5s\n[CV] END ..................C=100, max_iter=500, solver=lbfgs; total time=   4.6s\n[CV] END ..................C=100, max_iter=500, solver=lbfgs; total time=   4.5s\n[CV] END ..................C=100, max_iter=500, solver=lbfgs; total time=   4.9s\n[CV] END ..............C=100, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END ..............C=100, max_iter=500, solver=liblinear; total time=   0.5s\n[CV] END ..............C=100, max_iter=500, solver=liblinear; total time=   0.2s\n[CV] END ..............C=100, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END ..............C=100, max_iter=500, solver=liblinear; total time=   0.3s\n[CV] END .............C=100, max_iter=1000, solver=newton-cg; total time=  22.4s\n[CV] END .............C=100, max_iter=1000, solver=newton-cg; total time=  19.0s\n[CV] END .............C=100, max_iter=1000, solver=newton-cg; total time=  20.0s\n[CV] END .............C=100, max_iter=1000, solver=newton-cg; total time=  20.8s\n[CV] END .............C=100, max_iter=1000, solver=newton-cg; total time=  18.7s\n[CV] END .................C=100, max_iter=1000, solver=lbfgs; total time=   4.8s\n[CV] END .................C=100, max_iter=1000, solver=lbfgs; total time=   4.1s\n[CV] END .................C=100, max_iter=1000, solver=lbfgs; total time=   4.7s\n[CV] END .................C=100, max_iter=1000, solver=lbfgs; total time=   4.8s\n[CV] END .................C=100, max_iter=1000, solver=lbfgs; total time=   4.4s\n[CV] END .............C=100, max_iter=1000, solver=liblinear; total time=   0.5s\n[CV] END .............C=100, max_iter=1000, solver=liblinear; total time=   0.3s\n[CV] END .............C=100, max_iter=1000, solver=liblinear; total time=   0.4s\n[CV] END .............C=100, max_iter=1000, solver=liblinear; total time=   0.4s\n[CV] END .............C=100, max_iter=1000, solver=liblinear; total time=   0.2s\nBest Parameters for Logistic Regression: {'C': 0.01, 'max_iter': 100, 'solver': 'newton-cg'}\nBest Score for Logistic Regression: 0.5910995111638675\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]}],"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"hex_info":{"author":"Elu Gebre","project_id":"d4d16f54-4573-453e-a8de-ecb82a17c382","version":"draft","exported_date":"Sat Dec 09 2023 04:53:56 GMT+0000 (Coordinated Universal Time)"}},"nbformat":4,"nbformat_minor":4}